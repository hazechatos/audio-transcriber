{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e3c1b2",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "## Transcription\n",
    "\n",
    "We are using OpenAI Whisper-1 model using OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3dc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure your OpenAI API key is available as an environment variable\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"No OPENAI_API_KEY found\")\n",
    "    pass\n",
    "\n",
    "AUDIO_PATH = Path(\"data/set2/200327_7822.mp3\")\n",
    "assert AUDIO_PATH.exists(), f\"Audio file not found: {AUDIO_PATH}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838a1985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.audio.transcription.Transcription'>\n",
      "Donc on va déjà commencer par l'allée, l'accès à la partie jardin située à l'arrière de l'habitation du requérant. Alors c'est quoi ? C'est des petites pierres, c'est quoi que vous avez mis ? C'est des petits graviers, donc une allée en gravier qui est en bon état, l'accès est assez, il n'y a pas d'ornières, il n'y a pas de trous, et puis tout est bien aplati. J'ai une démarcation, alors vous m'avez dit avec des petites bordures métalliques, un bordure métallique qui fait la séparation entre l'espace végétal, herbe, et puis l'accès en gravier. Donc là je vois, certaines sont couvertes par l'herbe, alors on les retrouve.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Transcribe with whisper-1\n",
    "# Docs pattern: client.audio.transcriptions.create(model=\"whisper-1\", file=...)\n",
    "with open(AUDIO_PATH, \"rb\") as f:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=f,\n",
    "        language=\"fr\",           \n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "print(type(transcription))\n",
    "print(getattr(transcription, \"text\", transcription))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5087bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved transcript to: data\\set2\\200327_7822.txt\n"
     ]
    }
   ],
   "source": [
    "# Save transcript to a .txt next to the audio file\n",
    "output_txt = AUDIO_PATH.with_suffix(\".txt\")\n",
    "text = getattr(transcription, \"text\", None)\n",
    "\n",
    "if text is None and isinstance(transcription, dict):\n",
    "    text = transcription.get(\"text\")\n",
    "\n",
    "if not text:\n",
    "    raise RuntimeError(\"No transcription text received.\")\n",
    "\n",
    "output_txt.write_text(text, encoding=\"utf-8\")\n",
    "print(f\"Saved transcript to: {output_txt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c813f",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
